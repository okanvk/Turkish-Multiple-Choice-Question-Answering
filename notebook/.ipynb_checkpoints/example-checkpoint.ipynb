{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "20-oTWjrNMoj",
    "outputId": "20792e07-7f32-49e5-8017-ae52faa8d38c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==2.8.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
      "\r",
      "\u001b[K     |▋                               | 10kB 28.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 20kB 14.8MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 30kB 13.1MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 40kB 12.3MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 51kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 61kB 7.7MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 71kB 8.7MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 81kB 9.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 92kB 10.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 102kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 112kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 122kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 133kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 143kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 153kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 163kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 174kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 184kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 194kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 204kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 215kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 225kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 235kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 245kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 256kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 266kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 276kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 286kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 296kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 307kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 317kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 327kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 337kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 348kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 358kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 368kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 378kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 389kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 399kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 409kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 419kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 430kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 440kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 450kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 460kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 471kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 481kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 491kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 501kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 512kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 522kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 532kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 542kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 552kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 563kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 573kB 7.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.41.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.23.0)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 14.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n",
      "Collecting boto3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/df/6c160e21a5caa800de16f2aa859b92671623118b4d124639aeab06876c06/boto3-1.16.28-py2.py3-none-any.whl (129kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 34.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 22.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.8)\n",
      "Collecting tokenizers==0.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 42.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.11.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (0.17.0)\n",
      "Collecting botocore<1.20.0,>=1.19.28\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/e0/966b82eb9eab5fe36e80bcbbfda0d3f49cdd9ec896ebe9edb9824f896cd7/botocore-1.19.28-py2.py3-none-any.whl (7.0MB)\n",
      "\u001b[K     |████████████████████████████████| 7.0MB 57.3MB/s \n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 11.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.28->boto3->transformers==2.8.0) (2.8.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=bf7c9c7814a879e4179742a898d9f1db2bbf9c4436c71a135230e8bc92c42da6\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "\u001b[31mERROR: botocore 1.19.28 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: sacremoses, jmespath, botocore, s3transfer, boto3, sentencepiece, tokenizers, transformers\n",
      "Successfully installed boto3-1.16.28 botocore-1.19.28 jmespath-0.10.0 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.5.2 transformers-2.8.0\n",
      "Collecting tqdm==4.50.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/0e/ea53a3d6f1eb2cc31162c9ae89555cc26a3986e5559781f0b0df75aea5cf/tqdm-4.50.0-py2.py3-none-any.whl (70kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 5.2MB/s \n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "  Found existing installation: tqdm 4.41.1\n",
      "    Uninstalling tqdm-4.41.1:\n",
      "      Successfully uninstalled tqdm-4.41.1\n",
      "Successfully installed tqdm-4.50.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "tqdm"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
      "Collecting sentencepiece==0.1.91\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 8.0MB/s \n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "  Found existing installation: sentencepiece 0.1.94\n",
      "    Uninstalling sentencepiece-0.1.94:\n",
      "      Successfully uninstalled sentencepiece-0.1.94\n",
      "Successfully installed sentencepiece-0.1.91\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==2.8.0\n",
    "!pip install tqdm==4.50.0\n",
    "!pip install tokenizers==0.5.2       \n",
    "!pip install sentencepiece==0.1.91     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WG6DB3nWQ8sW",
    "outputId": "ff464521-d155-42c4-ce43-65bb6f6a8c38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'torch.version' from '/usr/local/lib/python3.6/dist-packages/torch/version.py'>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "print(torch.version)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpAkZOlXNQuu",
    "outputId": "5948dbc4-e6df-4af7-d8cb-e06a0f2be94a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BASE_DIR=./\n",
      "--2020-12-03 11:01:59--  https://raw.githubusercontent.com/mhardalov/exams-qa/main/scripts/experiments/utils_multiple_choice.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 21090 (21K) [text/plain]\n",
      "Saving to: ‘./utils_multiple_choice.py’\n",
      "\n",
      "utils_multiple_choi 100%[===================>]  20.60K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-12-03 11:01:59 (144 MB/s) - ‘./utils_multiple_choice.py’ saved [21090/21090]\n",
      "\n",
      "--2020-12-03 11:01:59--  https://raw.githubusercontent.com/mhardalov/exams-qa/main/scripts/experiments/run_multiple_choice.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 35852 (35K) [text/plain]\n",
      "Saving to: ‘./run_multiple_choice.py’\n",
      "\n",
      "run_multiple_choice 100%[===================>]  35.01K  --.-KB/s    in 0.002s  \n",
      "\n",
      "2020-12-03 11:01:59 (19.4 MB/s) - ‘./run_multiple_choice.py’ saved [35852/35852]\n",
      "\n",
      "--2020-12-03 11:01:59--  https://raw.githubusercontent.com/mhardalov/exams-qa/main/src/examsqa/models_multiple_choice.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5431 (5.3K) [text/plain]\n",
      "Saving to: ‘./models_multiple_choice.py’\n",
      "\n",
      "models_multiple_cho 100%[===================>]   5.30K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-12-03 11:02:00 (77.1 MB/s) - ‘./models_multiple_choice.py’ saved [5431/5431]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%env BASE_DIR=./\n",
    "# download\n",
    "def download_helpers():\n",
    "        !wget -P $BASE_DIR https://raw.githubusercontent.com/mhardalov/exams-qa/main/scripts/experiments/utils_multiple_choice.py\n",
    "        !wget -P $BASE_DIR https://raw.githubusercontent.com/mhardalov/exams-qa/main/scripts/experiments/run_multiple_choice.py\n",
    "        !wget -P $BASE_DIR https://raw.githubusercontent.com/mhardalov/exams-qa/main/src/examsqa/models_multiple_choice.py\n",
    "            \n",
    "download_helpers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HrUeiP8uNSg_"
   },
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!mkdir output\n",
    "!mkdir log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hwr503FSNSU1",
    "outputId": "666036a2-0f73-40bf-bd35-4c0027de5196"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-03 12:11:21.901505: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "12/03/2020 12:11:23 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "12/03/2020 12:11:23 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/dbmdz/bert-base-turkish-cased/config.json from cache at /root/.cache/torch/transformers/85e4250979fc6fb434f8348f81373dd92b27cfe72fec7a7b0cee0649e168bcd8.a3aeed7cdac4ab32c23e706965d9605a64756bbc94becd5f14a720ed9debae9a\n",
      "12/03/2020 12:11:23 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"_num_labels\": 6,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": \"exams\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "12/03/2020 12:11:23 - INFO - transformers.tokenization_utils -   Model name 'dbmdz/bert-base-turkish-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'dbmdz/bert-base-turkish-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "12/03/2020 12:11:25 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/dbmdz/bert-base-turkish-cased/vocab.txt from cache at /root/.cache/torch/transformers/66487ad4acd524c67592d438155765ba5c9c9bead20da0a74727a6bfeb85c62e.0df1d64abb373fc32402d72e6d347e1774e92e397d4dba7ee272c82288d22542\n",
      "12/03/2020 12:11:25 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/dbmdz/bert-base-turkish-cased/added_tokens.json from cache at None\n",
      "12/03/2020 12:11:25 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/dbmdz/bert-base-turkish-cased/special_tokens_map.json from cache at None\n",
      "12/03/2020 12:11:25 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/dbmdz/bert-base-turkish-cased/tokenizer_config.json from cache at /root/.cache/torch/transformers/b039cd41d4435c957bf3ba0561fa17dc57cf98648375a43eb90d8a93dc42e4eb.ee1046066e81360013c9d26b56704e3365efe857b2c657bd0f0b053f409c6f36\n",
      "12/03/2020 12:11:25 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/dbmdz/bert-base-turkish-cased/pytorch_model.bin from cache at /root/.cache/torch/transformers/f6fe084a944a2224d135f519bc5fa5036618b723bec62221fd3473607aa476eb.9fb1ef307024a3c812f422b3ffec42629ab5179875b506d731b8c9206bbfce55\n",
      "12/03/2020 12:11:29 - INFO - transformers.modeling_utils -   Weights of BertForMultipleChoice not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "12/03/2020 12:11:29 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMultipleChoice: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "12/03/2020 12:11:29 - INFO - root -   Arg Options:\n",
      "12/03/2020 12:11:29 - INFO - root -   opt: data_dir=./data\n",
      "opt: model_type=bert\n",
      "opt: model_name_or_path=dbmdz/bert-base-turkish-cased\n",
      "opt: task_name=exams\n",
      "opt: para_type=per_choice\n",
      "opt: output_predictions=True\n",
      "opt: output_dir=./outputs/\n",
      "opt: freeze_embeddings=False\n",
      "opt: freeze_layers=None\n",
      "opt: tb_log_dir=./logs/\n",
      "opt: config_name=\n",
      "opt: tokenizer_name=\n",
      "opt: cache_dir=\n",
      "opt: max_seq_length=256\n",
      "opt: do_train=True\n",
      "opt: do_eval=True\n",
      "opt: do_test=False\n",
      "opt: evaluate_during_training=True\n",
      "opt: do_lower_case=False\n",
      "opt: per_gpu_train_batch_size=8\n",
      "opt: per_gpu_eval_batch_size=8\n",
      "opt: gradient_accumulation_steps=1\n",
      "opt: learning_rate=5e-05\n",
      "opt: weight_decay=0.0\n",
      "opt: adam_epsilon=1e-08\n",
      "opt: max_grad_norm=1.0\n",
      "opt: num_train_epochs=5.0\n",
      "opt: max_steps=-1\n",
      "opt: warmup_proportion=0.0\n",
      "opt: logging_steps=1000\n",
      "opt: save_steps=1000\n",
      "opt: eval_all_checkpoints=False\n",
      "opt: no_cuda=False\n",
      "opt: overwrite_output_dir=True\n",
      "opt: overwrite_cache=True\n",
      "opt: seed=42\n",
      "opt: fp16=False\n",
      "opt: fp16_opt_level=O1\n",
      "opt: local_rank=-1\n",
      "opt: server_ip=\n",
      "opt: server_port=\n",
      "opt: n_gpu=1\n",
      "opt: device=cuda\n",
      "\n",
      "12/03/2020 12:11:34 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='./data', device=device(type='cuda'), do_eval=True, do_lower_case=False, do_test=False, do_train=True, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', freeze_embeddings=False, freeze_layers=None, gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=1000, max_grad_norm=1.0, max_seq_length=256, max_steps=-1, model_name_or_path='dbmdz/bert-base-turkish-cased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=5.0, output_dir='./outputs/', output_predictions=True, overwrite_cache=True, overwrite_output_dir=True, para_type='per_choice', per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, save_steps=1000, seed=42, server_ip='', server_port='', task_name='exams', tb_log_dir='./logs/', tokenizer_name='', warmup_proportion=0.0, weight_decay=0.0)\n",
      "12/03/2020 12:11:34 - INFO - __main__ -   Creating features from dataset file at ./data\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   LOOKING AT ./data train\n",
      "read arc data:   0% 0/3295 [00:00<?, ?it/s]12/03/2020 12:11:34 - INFO - utils_multiple_choice -   truth ERROR! @\n",
      "read arc data: 100% 3295/3295 [00:00<00:00, 18829.73it/s]\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   len examples: 3294}\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   Three choices: 0\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   Five choices: 1136\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   Other choices: 0\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   four choices: 2159\n",
      "12/03/2020 12:11:34 - INFO - __main__ -   Training number: 3294\n",
      "convert examples to features: 0it [00:00, ?it/s]12/03/2020 12:11:34 - INFO - utils_multiple_choice -   Writing example 0 of 3294\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   *** Example ***\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   race_id: 1c3b6d47-8571-11ea-a5d8-54bef70b159e\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   choice: 0\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   input_ids: 2 19383 2410 14579 2297 2716 4090 9816 19576 12 4595 2261 1022 26378 8519 13 3242 20722 18 27437 4595 2261 1022 27437 4595 2261 1022 12 72 18 24 4176 15394 1087 17 174 18 5991 6032 1025 22746 2052 16 14113 9230 2534 18 4388 8207 2065 2509 5352 14740 16 9012 25809 1998 15505 1988 2779 15941 25013 2686 23998 1024 2058 5848 15413 1980 18 4595 2261 1022 8298 2440 2707 2768 18 27437 4277 17735 4595 2261 1022 27437 4277 17735 4595 2261 1022 12 72 18 3245 4995 30810 16 15158 7921 31870 16 4724 31 174 18 6523 15493 4595 2261 1022 16 2681 3419 4595 2261 1022 26378 8519 2133 2054 5833 2716 4090 9816 26378 9057 1059 12979 1975 20461 22631 8012 22771 2029 2129 27437 4277 17735 4595 2261 1022 12 30810 17 20002 13 2074 6097 3781 4321 18 6523 15493 43 18 4595 2261 1022 6523 15493 4067 31857 4595 2261 1022 12 26 4393 27092 17 3638 4772 6467 13 16 8666 8012 22771 2029 2129 18 7233 11 3742 24961 2800 9412 22746 2052 14571 11520 12407 6695 5258 18 7233 11 3742 24961 2800 9412 22746 2052 14571 11520 12407 6695 5258 18 11729 12 14716 1052 13 2781 2133 4595 3 4595 2261 1022 22746 2052 8178 8843 2509 5352 14740 29003 12715 29045 35 19383 2410 14579 2228 3009 3671 50 4164 1052 1086 14372 3494 25831 2082 5505 4595 2261 1022 22746 2052 23998 7701 18 3\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   label: 3\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   choice: 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   input_ids: 2 19383 2410 14579 2297 2716 4090 9816 19576 12 4595 2261 1022 26378 8519 13 3242 20722 18 27437 4595 2261 1022 27437 4595 2261 1022 12 72 18 24 4176 15394 1087 17 174 18 5991 6032 1025 22746 2052 16 14113 9230 2534 18 4595 2261 1022 8298 2440 2707 2768 18 27437 4277 17735 4595 2261 1022 27437 4277 17735 4595 2261 1022 12 72 18 3245 4995 30810 16 15158 7921 31870 16 4724 31 174 18 6523 15493 4595 2261 1022 16 2681 3419 4595 2261 1022 26378 8519 2133 2054 5833 2716 4090 9816 26378 9057 1059 12979 1975 20461 22631 8012 22771 2029 2129 27437 4277 17735 4595 2261 1022 12 30810 17 20002 13 2074 6097 3781 4321 18 6523 15493 43 18 4595 2261 1022 6523 15493 4067 31857 4595 2261 1022 12 26 4393 27092 17 3638 4772 6467 13 16 8666 8012 22771 2029 2129 18 7233 11 3742 24961 2800 9412 22746 2052 14571 11520 12407 6695 5258 18 7233 11 3742 24961 2800 9412 22746 2052 14571 11520 12407 6695 5258 18 4595 2261 1022 26378 8519 16 24715 7652 2322 12223 16825 2586 30914 9370 2038 5669 7054 3054 6490 4090 1022 8204 5893 16 2308 5432 3704 1023 12223 16825 2586 30914 2716 2161 16794 3737 20722 18 27513 3 4595 2261 1022 22746 2052 8178 8843 2509 5352 14740 29003 12715 29045 35 9954 8650 1025 15098 2386 2183 10426 2747 1996 30721 1995 5113 2068 4118 18 3\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   label: 3\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   choice: 2\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   input_ids: 2 5032 5353 7956 2333 4093 24688 2509 5352 14740 16 29748 1009 2747 9620 2747 2985 2037 1992 8826 3038 18 2874 2917 4091 2054 2509 5352 14740 12 22380 30 12 12690 2900 13 6 7421 10150 3056 35 2874 4155 10822 2963 2751 10807 2458 2509 5352 14740 16 8012 3605 4900 2408 3759 2026 4748 12191 2077 18 6 6 22177 2509 5352 14740 1996 4484 2030 2140 1996 2474 6304 2133 3217 6627 18 2874 9121 2012 16 10114 31611 7621 17820 2026 4748 2509 5352 14740 5656 7971 12325 2067 18 2874 2856 9739 16 2747 16208 2509 5352 14740 3925 15329 6323 17951 3158 19416 18872 1992 3641 17022 1972 4623 4306 19297 31995 2516 18 2123 24688 2509 5352 14740 4389 12834 7913 2054 3038 18 3436 2509 5352 14740 2048 4400 31139 3523 3205 2556 18 13104 2761 6374 2079 3141 16214 2509 5352 14740 16 6374 2079 3028 2824 15434 2509 4728 30363 2002 18 22774 6522 1992 23618 6522 2509 5352 14740 1996 15648 23380 5795 18 2123 3795 4875 6138 2509 5352 14740 4174 10462 13770 1996 19377 2067 18 2123 4136 5945 14260 2509 5352 14740 21019 1980 2550 4884 1006 16112 1980 18 2123 4136 6639 14260 2509 5352 14740 21019 1980 2550 4884 3 4595 2261 1022 22746 2052 8178 8843 2509 5352 14740 29003 12715 29045 35 4595 2261 1022 22746 2052 4455 1996 11444 19251 16 1996 4922 2764 1024 29894 30236 1009 15318 10059 2071 2077 18 3\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   label: 3\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   choice: 3\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   input_ids: 2 27437 4595 2261 1022 27437 4595 2261 1022 12 72 18 24 4176 15394 1087 17 174 18 9022 2446 3043 1008 17 7176 1039 19251 2790 28041 1975 2048 19251 16 2048 13089 4595 2261 1022 26378 9057 1025 9864 18 5991 6032 1025 22746 2052 16 14113 9230 2534 18 4595 2261 1022 8298 2440 2707 2768 18 27437 4277 17735 4595 2261 1022 27437 4277 17735 4595 2261 1022 12 72 18 3245 4995 30810 16 15158 7921 31870 16 4724 31 174 18 6523 15493 4595 2261 1022 16 2681 3419 4595 2261 1022 26378 8519 2133 2054 5833 2716 4090 9816 26378 9057 1059 12979 1975 20461 22631 8012 22771 2029 2129 27437 4277 17735 4595 2261 1022 12 30810 17 20002 13 2074 6097 3781 4321 18 6523 15493 43 18 4595 2261 1022 6523 15493 4067 31857 4595 2261 1022 12 26 4393 27092 17 3638 4772 6467 13 16 8666 8012 22771 2029 2129 18 7233 11 3742 24961 2800 9412 22746 2052 14571 11520 12407 6695 5258 18 7233 11 3742 24961 2800 9412 22746 2052 14571 11520 12407 6695 5258 18 2123 2127 3048 1996 2542 16 2829 2510 4200 4455 20141 7657 4572 2509 5352 14740 14114 18 5983 4011 2204 2624 10804 1996 31454 22746 15179 16 3 4595 2261 1022 22746 2052 8178 8843 2509 5352 14740 29003 12715 29045 35 4595 2261 1022 22746 2052 3671 9878 30692 4538 14370 5617 12397 2553 16 14579 1971 4651 14370 2067 18 3\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   label: 3\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   choice: 4\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   input_ids: 2 27437 4595 2261 1022 27437 4595 2261 1022 12 72 18 24 4176 15394 1087 17 174 18 5991 6032 1025 22746 2052 16 14113 9230 2534 18 4595 2261 1022 8298 2440 2707 2768 18 27437 4277 17735 4595 2261 1022 27437 4277 17735 4595 2261 1022 12 72 18 3245 4995 30810 16 15158 7921 31870 16 4724 31 174 18 6523 15493 4595 2261 1022 16 2681 3419 4595 2261 1022 26378 8519 2133 2054 5833 2716 4090 9816 26378 9057 1059 12979 1975 20461 22631 8012 22771 2029 2129 27437 4277 17735 4595 2261 1022 12 30810 17 20002 13 2074 6097 3781 4321 18 6523 15493 43 18 4595 2261 1022 6523 15493 4067 31857 4595 2261 1022 12 26 4393 27092 17 3638 4772 6467 13 16 8666 8012 22771 2029 2129 18 7233 11 3742 24961 2800 9412 22746 2052 14571 11520 12407 6695 5258 18 7233 11 3742 24961 2800 9412 22746 2052 14571 11520 12407 6695 5258 18 11729 12 14716 1052 13 2781 2133 4595 2261 1022 16 6477 18 31816 12125 12736 27437 4595 2261 1022 21037 18 18404 1975 1050 16 12736 27437 4595 2261 1022 2058 9879 18 21090 1025 11867 1972 11 2567 4420 22746 2052 9591 16184 1985 2665 4053 4002 5524 2002 18 31847 17557 2462 5587 2509 5352 3 4595 2261 1022 22746 2052 8178 8843 2509 5352 14740 29003 12715 29045 35 4595 2261 1022 22746 2052 16 21679 1041 1052 1086 23998 1024 20722 18 3\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   label: 3\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   *** Example ***\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   race_id: 1c3b6d48-8571-11ea-a5d8-54bef70b159e\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   choice: 0\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   input_ids: 2 6 4100 22036 3205 1996 5686 1007 1988 30 6 16482 1986 1992 22380 1034 5134 1033 4456 22036 1996 3205 5686 1007 2072 2680 24473 1980 18 2319 11 2491 4456 22036 3652 2270 10849 11268 1991 11638 1048 16 6738 14502 22036 3340 28178 1026 3060 11 2054 2077 18 4100 22036 6241 2736 3341 1996 4683 3224 18 6096 16 4456 22036 18608 18337 2031 1996 12353 2912 5858 2524 18 11051 1054 16 3636 1996 4854 2074 4456 22036 15937 2112 18 16842 2288 1996 4456 22036 2048 19026 4484 18 12077 2248 4456 22036 6872 1980 18 4100 22036 16 30584 7439 12050 18 3714 2255 9870 4456 22036 3792 18 17680 4965 4456 22036 3792 18 18166 2261 2760 18868 18166 2261 2760 18868 16 18166 2261 2760 554 3742 4456 22036 16 2862 1996 10301 2080 2961 2838 6562 2067 18 4100 22036 2854 3445 4456 29074 2714 3931 2070 1992 12023 1065 1991 15837 23966 26202 11223 20005 11299 18 4100 22036 19527 1985 22170 2000 2133 24453 3200 16618 6057 1990 8304 18 2783 5078 22471 15725 4456 22036 1996 86 29501 29399 9879 18 4100 22036 3579 2538 1067 28872 2054 4800 18 48 6350 4488 18568 3 2281 10983 2270 7222 19535 1024 2154 6497 2030 2834 4045 2133 2862 1996 4646 1986 21697 16222 4456 554 22036 7198 18 8480 1986 4611 1986 29003 12715 6717 4456 16 22036 4611 2255 2696 2400 4627 2854 3992 1977 35 2389 7005 7317 4748 3\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   label: 2\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   choice: 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   input_ids: 2 6 4100 22036 3205 1996 5686 1007 1988 30 6 16482 1986 1992 22380 1034 5134 1033 4456 22036 1996 3205 5686 1007 2072 2680 24473 1980 18 2319 11 2491 4456 22036 3652 2270 10849 11268 1991 11638 1048 16 6738 14502 22036 3340 28178 1026 3060 11 2054 2077 18 4100 22036 6241 2736 3341 1996 4683 3224 18 6096 16 4456 22036 18608 18337 2031 1996 12353 2912 5858 2524 18 11051 1054 16 3636 1996 4854 2074 4456 22036 15937 2112 18 16842 2288 1996 4456 22036 2048 19026 4484 18 12077 2248 4456 22036 6872 1980 18 4100 22036 16 30584 7439 12050 18 3714 2255 9870 4456 22036 3792 18 17680 4965 4456 22036 3792 18 18166 2261 2760 18868 18166 2261 2760 18868 16 18166 2261 2760 554 3742 4456 22036 16 2862 1996 10301 2080 2961 2838 6562 2067 18 4100 22036 2854 3445 4456 29074 2714 3931 2070 1992 12023 1065 1991 15837 23966 26202 11223 20005 11299 18 4100 22036 19527 1985 22170 2000 2133 24453 3200 16618 6057 1990 8304 18 2783 5078 22471 15725 4456 22036 1996 86 29501 29399 9879 18 4100 22036 3579 2538 1067 28872 2054 4800 18 48 6350 4488 18568 3 2281 10983 2270 7222 19535 1024 2154 6497 2030 2834 4045 2133 2862 1996 4646 1986 21697 16222 4456 554 22036 7198 18 8480 1986 4611 1986 29003 12715 6717 4456 16 22036 4611 2255 2696 2400 4627 2854 3992 1977 35 9259 9109 1050 4748 3\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   label: 2\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   choice: 2\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   input_ids: 2 6 4100 22036 3205 1996 5686 1007 1988 30 6 16482 1986 1992 22380 1034 5134 1033 4456 22036 1996 3205 5686 1007 2072 2680 24473 1980 18 2319 11 2491 4456 22036 3652 2270 10849 11268 1991 11638 1048 16 6738 14502 22036 3340 28178 1026 3060 11 2054 2077 18 4100 22036 6241 2736 3341 1996 4683 3224 18 6096 16 4456 22036 18608 18337 2031 1996 12353 2912 5858 2524 18 11051 1054 16 3636 1996 4854 2074 4456 22036 15937 2112 18 16842 2288 1996 4456 22036 2048 19026 4484 18 12077 2248 4456 22036 6872 1980 18 4100 22036 16 30584 7439 12050 18 3714 2255 9870 4456 22036 3792 18 17680 4965 4456 22036 3792 18 18166 2261 2760 18868 18166 2261 2760 18868 16 18166 2261 2760 554 3742 4456 22036 16 2862 1996 10301 2080 2961 2838 6562 2067 18 4100 22036 2854 3445 4456 29074 2714 3931 2070 1992 12023 1065 1991 15837 23966 26202 11223 20005 11299 18 4100 22036 19527 1985 22170 2000 2133 24453 3200 16618 6057 1990 8304 18 2783 5078 22471 15725 4456 22036 1996 86 29501 29399 9879 18 4100 22036 3579 2538 1067 28872 2054 4800 18 48 3 2281 10983 2270 7222 19535 1024 2154 6497 2030 2834 4045 2133 2862 1996 4646 1986 21697 16222 4456 554 22036 7198 18 8480 1986 4611 1986 29003 12715 6717 4456 16 22036 4611 2255 2696 2400 4627 2854 3992 1977 35 2389 3423 2050 8834 14370 23953 21321 3\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   label: 2\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   choice: 3\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   input_ids: 2 6 4100 22036 3205 1996 5686 1007 1988 30 6 16482 1986 1992 22380 1034 5134 1033 4456 22036 1996 3205 5686 1007 2072 2680 24473 1980 18 2319 11 2491 4456 22036 3652 2270 10849 11268 1991 11638 1048 16 6738 14502 22036 3340 28178 1026 3060 11 2054 2077 18 4100 22036 6241 2736 3341 1996 4683 3224 18 6096 16 4456 22036 18608 18337 2031 1996 12353 2912 5858 2524 18 11051 1054 16 3636 1996 4854 2074 4456 22036 15937 2112 18 16842 2288 1996 4456 22036 2048 19026 4484 18 12077 2248 4456 22036 6872 1980 18 4100 22036 16 30584 7439 12050 18 3714 2255 9870 4456 22036 3792 18 17680 4965 4456 22036 3792 18 18166 2261 2760 18868 18166 2261 2760 18868 16 18166 2261 2760 554 3742 4456 22036 16 2862 1996 10301 2080 2961 2838 6562 2067 18 4100 22036 2854 3445 4456 29074 2714 3931 2070 1992 12023 1065 1991 15837 23966 26202 11223 20005 11299 18 4100 22036 19527 1985 22170 2000 2133 24453 3200 16618 6057 1990 8304 18 2783 5078 22471 15725 4456 22036 1996 86 29501 29399 9879 18 4100 22036 3579 2538 1067 28872 2054 4800 18 48 3 2281 10983 2270 7222 19535 1024 2154 6497 2030 2834 4045 2133 2862 1996 4646 1986 21697 16222 4456 554 22036 7198 18 8480 1986 4611 1986 29003 12715 6717 4456 16 22036 4611 2255 2696 2400 4627 2854 3992 1977 35 26643 2184 2436 2846 8796 1973 9062 3\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   label: 2\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   choice: 4\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   input_ids: 2 6 4100 22036 3205 1996 5686 1007 1988 30 6 16482 1986 1992 22380 1034 5134 1033 4456 22036 1996 3205 5686 1007 2072 2680 24473 1980 18 2319 11 2491 4456 22036 3652 2270 10849 11268 1991 11638 1048 16 6738 14502 22036 3340 28178 1026 3060 11 2054 2077 18 4100 22036 6241 2736 3341 1996 4683 3224 18 6096 16 4456 22036 18608 18337 2031 1996 12353 2912 5858 2524 18 11051 1054 16 3636 1996 4854 2074 4456 22036 15937 2112 18 16842 2288 1996 4456 22036 2048 19026 4484 18 12077 2248 4456 22036 6872 1980 18 4100 22036 16 30584 7439 12050 18 3714 2255 9870 4456 22036 3792 18 17680 4965 4456 22036 3792 18 18166 2261 2760 18868 18166 2261 2760 18868 16 18166 2261 2760 554 3742 4456 22036 16 2862 1996 10301 2080 2961 2838 6562 2067 18 4100 22036 2854 3445 4456 29074 2714 3931 2070 1992 12023 1065 1991 15837 23966 26202 11223 20005 11299 18 4100 22036 19527 1985 22170 2000 2133 24453 3200 16618 6057 1990 8304 18 2783 5078 22471 15725 4456 22036 1996 86 29501 29399 9879 18 4100 22036 3579 2538 1067 28872 2054 4800 18 48 6350 4488 3 2281 10983 2270 7222 19535 1024 2154 6497 2030 2834 4045 2133 2862 1996 4646 1986 21697 16222 4456 554 22036 7198 18 8480 1986 4611 1986 29003 12715 6717 4456 16 22036 4611 2255 2696 2400 4627 2854 3992 1977 35 8873 2108 5406 6462 9783 3\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/03/2020 12:11:34 - INFO - utils_multiple_choice -   label: 2\n",
      "convert examples to features: 3294it [01:47, 30.67it/s]\n",
      "12/03/2020 12:13:21 - INFO - __main__ -   Saving features into cached file ./data/cached_train_dbmdz__bert-base-turkish-cased_256_exams\n",
      "12/03/2020 12:13:25 - INFO - __main__ -   ***** Running training *****\n",
      "12/03/2020 12:13:25 - INFO - __main__ -     Num examples = 3294\n",
      "12/03/2020 12:13:25 - INFO - __main__ -     Num Epochs = 5\n",
      "12/03/2020 12:13:25 - INFO - __main__ -     Instantaneous batch size per GPU = 8\n",
      "12/03/2020 12:13:25 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "12/03/2020 12:13:25 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "12/03/2020 12:13:25 - INFO - __main__ -     Total optimization steps = 2060\n",
      "Epoch:   0% 0/5 [00:00<?, ?it/s]\n",
      "Iteration:   0% 0/412 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
      "\n",
      "Iteration:   0% 1/412 [00:00<06:46,  1.01it/s]\u001b[A\n",
      "Iteration:   0% 2/412 [00:01<06:40,  1.02it/s]\u001b[A\n",
      "Iteration:   1% 3/412 [00:02<06:37,  1.03it/s]\u001b[A\n",
      "Iteration:   1% 4/412 [00:03<06:34,  1.04it/s]\u001b[A\n",
      "Iteration:   1% 5/412 [00:04<06:31,  1.04it/s]\u001b[A\n",
      "Iteration:   1% 6/412 [00:05<06:29,  1.04it/s]\u001b[A\n",
      "Iteration:   2% 7/412 [00:06<06:28,  1.04it/s]\u001b[A\n",
      "Iteration:   2% 8/412 [00:07<06:26,  1.04it/s]\u001b[A\n",
      "Iteration:   2% 9/412 [00:08<06:25,  1.05it/s]\u001b[A\n",
      "Iteration:   2% 10/412 [00:09<06:24,  1.05it/s]\u001b[A\n",
      "Iteration:   3% 11/412 [00:10<06:23,  1.05it/s]\u001b[A\n",
      "Iteration:   3% 12/412 [00:11<06:22,  1.05it/s]\u001b[A\n",
      "Iteration:   3% 13/412 [00:12<06:21,  1.04it/s]\u001b[A\n",
      "Iteration:   3% 14/412 [00:13<06:20,  1.04it/s]\u001b[A\n",
      "Iteration:   4% 15/412 [00:14<06:21,  1.04it/s]\u001b[A\n",
      "Iteration:   4% 16/412 [00:15<06:19,  1.04it/s]\u001b[A\n",
      "Iteration:   4% 17/412 [00:16<06:18,  1.04it/s]\u001b[A\n",
      "Iteration:   4% 18/412 [00:17<06:17,  1.04it/s]\u001b[A\n",
      "Iteration:   5% 19/412 [00:18<06:15,  1.05it/s]\u001b[A\n",
      "Iteration:   5% 20/412 [00:19<06:15,  1.04it/s]\u001b[A\n",
      "Iteration:   5% 21/412 [00:20<06:13,  1.05it/s]\u001b[A\n",
      "Iteration:   5% 22/412 [00:21<06:12,  1.05it/s]\u001b[A\n",
      "Iteration:   6% 23/412 [00:22<06:11,  1.05it/s]\u001b[A\n",
      "Iteration:   6% 24/412 [00:22<06:10,  1.05it/s]\u001b[A\n",
      "Iteration:   6% 25/412 [00:23<06:09,  1.05it/s]\u001b[A\n",
      "Iteration:   6% 26/412 [00:24<06:09,  1.04it/s]\u001b[A\n",
      "Iteration:   7% 27/412 [00:25<06:08,  1.05it/s]\u001b[A\n",
      "Iteration:   7% 28/412 [00:26<06:07,  1.04it/s]\u001b[A\n",
      "Iteration:   7% 29/412 [00:27<06:05,  1.05it/s]\u001b[A\n",
      "Iteration:   7% 30/412 [00:28<06:04,  1.05it/s]\u001b[A\n",
      "Iteration:   8% 31/412 [00:29<06:03,  1.05it/s]\u001b[A\n",
      "Iteration:   8% 32/412 [00:30<06:03,  1.05it/s]\u001b[A\n",
      "Iteration:   8% 33/412 [00:31<06:03,  1.04it/s]\u001b[A\n",
      "Iteration:   8% 34/412 [00:32<06:02,  1.04it/s]\u001b[A\n",
      "Iteration:   8% 35/412 [00:33<06:00,  1.05it/s]\u001b[A\n",
      "Iteration:   9% 36/412 [00:34<05:59,  1.05it/s]\u001b[A\n",
      "Iteration:   9% 37/412 [00:35<05:58,  1.04it/s]\u001b[A\n",
      "Iteration:   9% 38/412 [00:36<05:57,  1.05it/s]\u001b[A\n",
      "Iteration:   9% 39/412 [00:37<05:56,  1.05it/s]\u001b[A\n",
      "Iteration:  10% 40/412 [00:38<05:55,  1.05it/s]\u001b[A\n",
      "Iteration:  10% 41/412 [00:39<05:54,  1.05it/s]\u001b[A\n",
      "Iteration:  10% 42/412 [00:40<05:53,  1.05it/s]\u001b[A\n",
      "Iteration:  10% 43/412 [00:41<05:52,  1.05it/s]\u001b[A\n",
      "Iteration:  11% 44/412 [00:42<05:51,  1.05it/s]\u001b[A\n",
      "Iteration:  11% 45/412 [00:43<05:50,  1.05it/s]\u001b[A\n",
      "Iteration:  11% 46/412 [00:44<05:50,  1.04it/s]\u001b[A\n",
      "Iteration:  11% 47/412 [00:44<05:50,  1.04it/s]\u001b[A\n",
      "Iteration:  12% 48/412 [00:45<05:48,  1.05it/s]\u001b[A\n",
      "Iteration:  12% 49/412 [00:46<05:47,  1.05it/s]\u001b[A\n",
      "Iteration:  12% 50/412 [00:47<05:45,  1.05it/s]\u001b[A\n",
      "Iteration:  12% 51/412 [00:48<05:45,  1.04it/s]\u001b[A\n",
      "Iteration:  13% 52/412 [00:49<05:45,  1.04it/s]\u001b[A\n",
      "Iteration:  13% 53/412 [00:50<05:43,  1.05it/s]\u001b[A\n",
      "Iteration:  13% 54/412 [00:51<05:42,  1.05it/s]\u001b[A\n",
      "Iteration:  13% 55/412 [00:52<05:41,  1.05it/s]\u001b[A\n",
      "Iteration:  14% 56/412 [00:53<05:40,  1.04it/s]\u001b[A\n",
      "Iteration:  14% 57/412 [00:54<05:40,  1.04it/s]\u001b[A\n",
      "Iteration:  14% 58/412 [00:55<05:38,  1.04it/s]\u001b[A\n",
      "Iteration:  14% 59/412 [00:56<05:36,  1.05it/s]\u001b[A\n",
      "Iteration:  15% 60/412 [00:57<05:36,  1.05it/s]\u001b[A\n",
      "Iteration:  15% 61/412 [00:58<05:35,  1.05it/s]\u001b[A\n",
      "Iteration:  15% 62/412 [00:59<05:34,  1.05it/s]\u001b[A\n",
      "Iteration:  15% 63/412 [01:00<05:33,  1.05it/s]\u001b[A\n",
      "Iteration:  16% 64/412 [01:01<05:33,  1.04it/s]\u001b[A\n",
      "Iteration:  16% 65/412 [01:02<05:31,  1.05it/s]\u001b[A\n",
      "Iteration:  16% 66/412 [01:03<05:30,  1.05it/s]\u001b[A\n",
      "Iteration:  16% 67/412 [01:04<05:29,  1.05it/s]\u001b[A\n",
      "Iteration:  17% 68/412 [01:05<05:29,  1.05it/s]\u001b[A\n",
      "Iteration:  17% 69/412 [01:06<05:27,  1.05it/s]\u001b[A\n",
      "Iteration:  17% 70/412 [01:06<05:26,  1.05it/s]\u001b[A\n",
      "Iteration:  17% 71/412 [01:07<05:25,  1.05it/s]\u001b[A\n",
      "Iteration:  17% 72/412 [01:08<05:23,  1.05it/s]\u001b[A\n",
      "Iteration:  18% 73/412 [01:09<05:22,  1.05it/s]\u001b[A\n",
      "Iteration:  18% 74/412 [01:10<05:22,  1.05it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "!python ./run_multiple_choice.py \\\n",
    "    --model_type bert \\\n",
    "    --task_name exams \\\n",
    "    --model_name_or_path dbmdz/bert-base-turkish-cased \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --evaluate_during_training \\\n",
    "    --logging_steps 1000 \\\n",
    "    --save_steps 1000 \\\n",
    "    --data_dir ./data \\\n",
    "    --num_train_epochs 5 \\\n",
    "    --max_seq_length 256 \\\n",
    "    --output_dir ./output/ \\\n",
    "    --overwrite_cache \\\n",
    "    --tb_log_dir ./log/ \\\n",
    "    --per_gpu_eval_batch_size=8 \\\n",
    "    --per_gpu_train_batch_size=8 \\\n",
    "    --overwrite_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QnZHxD0_NS_I",
    "outputId": "b97265b5-85a8-4e0f-fe0a-512f3ce1d4fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.18.5)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.4.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.10.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.35.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (50.3.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.33.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.12.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.15.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.3.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.17.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (2020.11.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard) (2.0.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "2020-12-03 12:08:10.111781: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.3.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard\n",
    "!tensorboard --logdir=./log/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XIGFz18-gGGy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
